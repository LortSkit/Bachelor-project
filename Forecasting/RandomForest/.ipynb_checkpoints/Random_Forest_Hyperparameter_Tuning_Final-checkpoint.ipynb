{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e749fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python39\\site-packages\\statsmodels\\compat\\pandas.py:61: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "mpl.rcParams['font.size'] = 16  # Set the font size for all elements\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "#For random forest for time series:\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "\n",
    "#For metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Having to import from subfolders of parent directories is a nightmare\n",
    "import sys\n",
    "import os\n",
    "current = os.path.dirname(os.path.realpath(\"Random_Forest_Hyperparameter_Tuning_Final.ipynb\"))\n",
    "parent = os.path.dirname(os.path.dirname(current))\n",
    "sys.path.append(parent+\"\\Functions\")\n",
    "\n",
    "#From Functions folder\n",
    "from LoadSeries import load_series, moving_average\n",
    "from Merge import merge\n",
    "from Battery import Battery\n",
    "from DPModel import DP, DP_carb, DP_both\n",
    "from Logic import logic_rollout, action_rollout, pred_logic_rollout, print_price_summary, logic_series_print\n",
    "from MPC import MPC, MPC_carb, MPC_both, MPCModel\n",
    "from Predictions import RF\n",
    "from SARIMAfx import SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aeeef6",
   "metadata": {},
   "source": [
    "# House h16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8573db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RF(\"h16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2360b0ee",
   "metadata": {},
   "source": [
    "## 2021 July 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57191993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:13<00:00, 14.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 22.27594180744192\n",
      "\n",
      "Time spent so far 73.87308192253113s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:26<00:00, 17.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 713, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 42.181179166759954\n",
      "\n",
      "Time spent so far 161.88896369934082s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:36<00:00, 19.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 23.583689457212824\n",
      "\n",
      "Time spent so far 258.7589044570923s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:58<00:00, 23.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 24.96835855452034\n",
      "\n",
      "Time spent so far 378.12967014312744s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:38<00:00, 31.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 633, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 32.470583224390445\n",
      "\n",
      "Time spent so far 538.3450860977173s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:44<00:00, 32.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 713, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 30.916291267243945\n",
      "\n",
      "Time spent so far 706.1569833755493s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "Best parameters = {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"p\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40042315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:12<00:00, 14.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 1.4361039539045741\n",
      "\n",
      "Time spent so far 73.20059752464294s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:28<00:00, 17.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 402, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 1.5416104923953722\n",
      "\n",
      "Time spent so far 162.7824902534485s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:41<00:00, 20.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 1.6327147388241698\n",
      "\n",
      "Time spent so far 264.8608765602112s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:10<00:00, 26.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n",
      "  Backtesting metric: 1.7304974033493072\n",
      "\n",
      "Time spent so far 396.6514754295349s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:38<00:00, 31.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 1.6768730805368826\n",
      "\n",
      "Time spent so far 556.1904761791229s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [03:07<00:00, 37.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 1.5071603681998493\n",
      "\n",
      "Time spent so far 744.7980804443359s\n",
      "Best training size = 100\n",
      "Best lags = [1 2 3 4 5 6]\n",
      "Best parameters = {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"c\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b50da534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:13<00:00, 14.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 129.54395999955935\n",
      "\n",
      "Time spent so far 74.08170485496521s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:27<00:00, 17.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 142.11356751719492\n",
      "\n",
      "Time spent so far 162.46854972839355s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:43<00:00, 20.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 153.27565106806563\n",
      "\n",
      "Time spent so far 268.1081874370575s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:15<00:00, 27.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 156.09126689874714\n",
      "\n",
      "Time spent so far 405.25605154037476s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:50<00:00, 34.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 177.59408052796186\n",
      "\n",
      "Time spent so far 578.2279529571533s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [03:19<00:00, 39.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 310.7426057969779\n",
      "\n",
      "Time spent so far 781.8521082401276s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Best parameters = {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"e\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d51fa4",
   "metadata": {},
   "source": [
    "## 2022 Decm 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee2530e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:11<00:00, 14.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.06247221410757257\n",
      "\n",
      "Time spent so far 72.42041373252869s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:18<00:00, 15.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 633, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.2582948385199571\n",
      "\n",
      "Time spent so far 151.59860944747925s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:32<00:00, 18.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.07932788145910226\n",
      "\n",
      "Time spent so far 244.9245011806488s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:46<00:00, 21.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 713, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.1391664345689556\n",
      "\n",
      "Time spent so far 352.6769468784332s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:17<00:00, 27.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 633, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.26162768478588777\n",
      "\n",
      "Time spent so far 491.8184611797333s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:40<00:00, 32.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 633, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.26236010898696793\n",
      "\n",
      "Time spent so far 654.0719990730286s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Best parameters = {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"p\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c66bf84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:12<00:00, 14.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 1.3357022422322204\n",
      "\n",
      "Time spent so far 72.76852631568909s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:26<00:00, 17.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 418, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 1.1870392843965913\n",
      "\n",
      "Time spent so far 159.6889317035675s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:41<00:00, 20.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n",
      "  Backtesting metric: 1.5773100922436276\n",
      "\n",
      "Time spent so far 262.77833890914917s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:12<00:00, 26.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 1.495771630785292\n",
      "\n",
      "Time spent so far 396.389954328537s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:41<00:00, 32.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 1.646985674425365\n",
      "\n",
      "Time spent so far 561.4802756309509s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [03:11<00:00, 38.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n",
      "  Backtesting metric: 1.7180416960972449\n",
      "\n",
      "Time spent so far 756.2488677501678s\n",
      "Best training size = 500\n",
      "Best lags = [1 2 3 4 5 6]\n",
      "Best parameters = {'n_estimators': 418, 'max_depth': 13, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"c\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6111d844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:12<00:00, 14.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 11367.724796243492\n",
      "\n",
      "Time spent so far 73.04222249984741s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:26<00:00, 17.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 713, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 8274.462267029145\n",
      "\n",
      "Time spent so far 161.2359721660614s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:45<00:00, 21.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 7631.793137423374\n",
      "\n",
      "Time spent so far 267.4986402988434s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:18<00:00, 27.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 3666.4049545676967\n",
      "\n",
      "Time spent so far 406.93569898605347s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:54<00:00, 34.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 7104.064018833935\n",
      "\n",
      "Time spent so far 583.1459159851074s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [03:26<00:00, 41.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 5738.858039510484\n",
      "\n",
      "Time spent so far 790.7490632534027s\n",
      "Best training size = 2000\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Best parameters = {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"e\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db9f6c",
   "metadata": {},
   "source": [
    "## 2021 Aprl 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa04c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-04-08 00:00:00 to 2021-04-08 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:08<00:00, 13.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 3.887162296213368\n",
      "\n",
      "Time spent so far 68.94308233261108s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:17<00:00, 15.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 4.573661549269825\n",
      "\n",
      "Time spent so far 147.25093817710876s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:28<00:00, 17.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 633, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 5.20354805040912\n",
      "\n",
      "Time spent so far 236.76195216178894s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:42<00:00, 20.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 402, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 3.6773612450852653\n",
      "\n",
      "Time spent so far 340.82401180267334s\n",
      "Best training size = 1800\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Best parameters = {'n_estimators': 402, 'max_depth': 13, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"p\", Start = '2021-04-08 00:00:00', End = '2021-04-08 23:00:00',train_sizes=[100,500,1000,1800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41128ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-04-08 00:00:00 to 2021-04-08 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:07<00:00, 13.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 2.101293352914428\n",
      "\n",
      "Time spent so far 67.95677971839905s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:21<00:00, 16.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 2.6270175255439727\n",
      "\n",
      "Time spent so far 149.78902649879456s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:36<00:00, 19.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n",
      "  Backtesting metric: 2.707517610466924\n",
      "\n",
      "Time spent so far 247.65173840522766s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:00<00:00, 24.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n",
      "  Backtesting metric: 2.6078073634440018\n",
      "\n",
      "Time spent so far 369.58964109420776s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Best parameters = {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"c\", Start = '2021-04-08 00:00:00', End = '2021-04-08 23:00:00',train_sizes=[100,500,1000,1800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "287470e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-04-08 00:00:00 to 2021-04-08 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:08<00:00, 13.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 279.48918917242037\n",
      "\n",
      "Time spent so far 68.92721247673035s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:23<00:00, 16.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 281.69674662453315\n",
      "\n",
      "Time spent so far 152.55210256576538s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:42<00:00, 20.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 329.96232217288946\n",
      "\n",
      "Time spent so far 256.15095615386963s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:22<00:00, 28.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 325.5345559033072\n",
      "\n",
      "Time spent so far 399.696985244751s\n",
      "Best training size = 100\n",
      "Best lags = [1]\n",
      "Best parameters = {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"e\", Start = '2021-04-08 00:00:00', End = '2021-04-08 23:00:00',train_sizes=[100,500,1000,1800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d58131",
   "metadata": {},
   "source": [
    "## 2021 Oct 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2eb0c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-10-08 00:00:00 to 2021-10-08 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:10<00:00, 14.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n",
      "  Backtesting metric: 17.32508226735509\n",
      "\n",
      "Time spent so far 70.60757803916931s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:16<00:00, 15.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 7.911527679354919\n",
      "\n",
      "Time spent so far 147.45767092704773s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:30<00:00, 18.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 8.545463399903857\n",
      "\n",
      "Time spent so far 238.76942420005798s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:00<00:00, 24.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 8.589001942714406\n",
      "\n",
      "Time spent so far 361.7649779319763s\n",
      "Best training size = 500\n",
      "Best lags = [1]\n",
      "Best parameters = {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"p\", Start = '2021-10-08 00:00:00', End = '2021-10-08 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c11b86cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-10-08 00:00:00 to 2021-10-08 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:14<00:00, 14.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 713, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.5229107717104693\n",
      "\n",
      "Time spent so far 75.31880235671997s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:28<00:00, 17.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.5772005788792947\n",
      "\n",
      "Time spent so far 164.44836020469666s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:45<00:00, 21.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.5328333759788423\n",
      "\n",
      "Time spent so far 271.5280792713165s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:18<00:00, 27.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.5091424209293917\n",
      "\n",
      "Time spent so far 411.74418020248413s\n",
      "Best training size = 2000\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Best parameters = {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"c\", Start = '2021-10-08 00:00:00', End = '2021-10-08 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de1cdb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-10-08 00:00:00 to 2021-10-08 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:16<00:00, 15.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 402, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 119.90893388549752\n",
      "\n",
      "Time spent so far 76.50094056129456s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:31<00:00, 18.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 418, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 161.79972280153424\n",
      "\n",
      "Time spent so far 168.59595775604248s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:43<00:00, 20.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 190.3547763753232\n",
      "\n",
      "Time spent so far 273.1089417934418s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:20<00:00, 28.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 286.0787923436213\n",
      "\n",
      "Time spent so far 414.5489296913147s\n",
      "Best training size = 100\n",
      "Best lags = [1]\n",
      "Best parameters = {'n_estimators': 402, 'max_depth': 13, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"e\", Start = '2021-10-08 00:00:00', End = '2021-10-08 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057f886e",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3cc5a",
   "metadata": {},
   "source": [
    "# House h28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13dd9ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RF(\"h28\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d433d",
   "metadata": {},
   "source": [
    "## 2021 July 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b642f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:12<00:00, 14.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 633, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 8.866294472173704\n",
      "\n",
      "Time spent so far 73.17209672927856s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:21<00:00, 16.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 13.325685717678539\n",
      "\n",
      "Time spent so far 155.6019320487976s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:36<00:00, 19.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 713, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 10.36616943898865\n",
      "\n",
      "Time spent so far 253.70414185523987s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:02<00:00, 24.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 12.14737331075897\n",
      "\n",
      "Time spent so far 376.4040005207062s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "Best parameters = {'n_estimators': 633, 'max_depth': 9, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"p\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e031b782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:13<00:00, 14.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 2.323344749476408\n",
      "\n",
      "Time spent so far 74.24428033828735s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:25<00:00, 17.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 402, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 3.362111379816419\n",
      "\n",
      "Time spent so far 160.43680238723755s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:41<00:00, 20.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 2.2416826419178633\n",
      "\n",
      "Time spent so far 262.96864342689514s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:11<00:00, 26.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n",
      "  Backtesting metric: 2.5147193056092134\n",
      "\n",
      "Time spent so far 396.3131935596466s\n",
      "Best training size = 1000\n",
      "Best lags = [1]\n",
      "Best parameters = {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"c\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "728d5173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:12<00:00, 14.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 129.54395999955935\n",
      "\n",
      "Time spent so far 72.86182832717896s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:27<00:00, 17.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 142.11356751719492\n",
      "\n",
      "Time spent so far 160.48849534988403s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:43<00:00, 20.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 153.27565106806563\n",
      "\n",
      "Time spent so far 265.69484305381775s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:19<00:00, 27.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 156.09126689874714\n",
      "\n",
      "Time spent so far 406.0670597553253s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Best parameters = {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"e\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595ad36",
   "metadata": {},
   "source": [
    "## 2022 Decm 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01a3408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:13<00:00, 14.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.024351521360873245\n",
      "\n",
      "Time spent so far 74.03166723251343s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:18<00:00, 15.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.04484145058443217\n",
      "\n",
      "Time spent so far 153.02274107933044s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:26<00:00, 17.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 402, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.017882935396733735\n",
      "\n",
      "Time spent so far 240.17496919631958s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:44<00:00, 20.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.08901530490759275\n",
      "\n",
      "Time spent so far 345.6098816394806s\n",
      "Best training size = 1000\n",
      "Best lags = [1 2 3 4 5 6]\n",
      "Best parameters = {'n_estimators': 402, 'max_depth': 13, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"p\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32949505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:10<00:00, 14.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 4.827838018005088\n",
      "\n",
      "Time spent so far 70.92103505134583s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:29<00:00, 17.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 4.71137083245518\n",
      "\n",
      "Time spent so far 161.37085819244385s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:35<00:00, 19.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n",
      "  Backtesting metric: 4.646320625273935\n",
      "\n",
      "Time spent so far 257.7989001274109s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:06<00:00, 25.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 4.647742743730373\n",
      "\n",
      "Time spent so far 385.34978795051575s\n",
      "Best training size = 1000\n",
      "Best lags = [1 2 3 4 5 6]\n",
      "Best parameters = {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"c\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44b6c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:08<00:00, 13.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 11367.724796243492\n",
      "\n",
      "Time spent so far 68.7077705860138s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:22<00:00, 16.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 713, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 8274.462267029145\n",
      "\n",
      "Time spent so far 152.03722167015076s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:39<00:00, 19.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 7631.793137423374\n",
      "\n",
      "Time spent so far 252.77165865898132s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:09<00:00, 25.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 3666.4049545676967\n",
      "\n",
      "Time spent so far 383.5630376338959s\n",
      "Best training size = 2000\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Best parameters = {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"e\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bde40e",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d913c685",
   "metadata": {},
   "source": [
    "# House h22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec4c3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RF(\"h22\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c73c4",
   "metadata": {},
   "source": [
    "## 2021 July 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa32df6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:07<00:00, 13.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 402, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 8.318479444099045\n",
      "\n",
      "Time spent so far 68.42607855796814s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:19<00:00, 15.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 19.79195246021082\n",
      "\n",
      "Time spent so far 148.43619561195374s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:36<00:00, 19.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 14.086857976026144\n",
      "\n",
      "Time spent so far 245.8100061416626s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:57<00:00, 23.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 16.918296824469284\n",
      "\n",
      "Time spent so far 364.18430829048157s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "Best parameters = {'n_estimators': 402, 'max_depth': 13, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"p\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edf7afad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:08<00:00, 13.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 4.371945619503426\n",
      "\n",
      "Time spent so far 69.0701310634613s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:21<00:00, 16.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 713, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 5.308564576623964\n",
      "\n",
      "Time spent so far 151.59606957435608s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:36<00:00, 19.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 5.215416220805415\n",
      "\n",
      "Time spent so far 250.32024431228638s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:04<00:00, 24.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 633, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 5.117836943023146\n",
      "\n",
      "Time spent so far 377.2106087207794s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "Best parameters = {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"c\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c58329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:09<00:00, 13.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 129.54395999955935\n",
      "\n",
      "Time spent so far 69.71700191497803s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:22<00:00, 16.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 142.11356751719492\n",
      "\n",
      "Time spent so far 152.90897941589355s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:38<00:00, 19.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 153.27565106806563\n",
      "\n",
      "Time spent so far 253.22490906715393s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:10<00:00, 26.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 156.09126689874714\n",
      "\n",
      "Time spent so far 384.9718189239502s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Best parameters = {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"e\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a02c7c",
   "metadata": {},
   "source": [
    "## 2022 Decm 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce25f00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:06<00:00, 13.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.040182463731420086\n",
      "\n",
      "Time spent so far 66.96550846099854s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:11<00:00, 14.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.08389697654449042\n",
      "\n",
      "Time spent so far 138.65957140922546s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:19<00:00, 15.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.041385544986902535\n",
      "\n",
      "Time spent so far 218.47213077545166s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:37<00:00, 19.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 493, 'max_depth': 15, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.05881591952434458\n",
      "\n",
      "Time spent so far 316.867294549942s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Best parameters = {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"p\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0f5669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:09<00:00, 13.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 633, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 5.651477176358384\n",
      "\n",
      "Time spent so far 69.95640015602112s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:22<00:00, 16.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 418, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 5.1155969211621\n",
      "\n",
      "Time spent so far 153.62857127189636s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:37<00:00, 19.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 4.932004663936851\n",
      "\n",
      "Time spent so far 252.27428531646729s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:06<00:00, 25.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 5.091165752299405\n",
      "\n",
      "Time spent so far 379.46968936920166s\n",
      "Best training size = 1000\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Best parameters = {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"c\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d60f123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:08<00:00, 13.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 11367.724796243492\n",
      "\n",
      "Time spent so far 68.6974470615387s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:21<00:00, 16.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 713, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 8274.462267029145\n",
      "\n",
      "Time spent so far 151.81359481811523s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:38<00:00, 19.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 7631.793137423374\n",
      "\n",
      "Time spent so far 251.44413471221924s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:07<00:00, 25.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 3666.4049545676967\n",
      "\n",
      "Time spent so far 380.32123374938965s\n",
      "Best training size = 2000\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Best parameters = {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"e\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ab53a3",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944bb01e",
   "metadata": {},
   "source": [
    "# House h32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e564df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RF(\"h32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80e941",
   "metadata": {},
   "source": [
    "## 2021 July 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bcff102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:07<00:00, 13.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 418, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 6.5942336127236025\n",
      "\n",
      "Time spent so far 67.8669855594635s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:18<00:00, 15.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 11.253346001868492\n",
      "\n",
      "Time spent so far 147.05404925346375s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:32<00:00, 18.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 720, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 8.927118081170711\n",
      "\n",
      "Time spent so far 241.07441520690918s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:55<00:00, 23.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 9.495866039656368\n",
      "\n",
      "Time spent so far 357.41166639328003s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "Best parameters = {'n_estimators': 418, 'max_depth': 13, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"p\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b735a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:06<00:00, 13.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 418, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 3.5670358961539126\n",
      "\n",
      "Time spent so far 67.20278358459473s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:20<00:00, 16.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 2.700525404452035\n",
      "\n",
      "Time spent so far 148.16105365753174s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:35<00:00, 19.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 3.0216138964808987\n",
      "\n",
      "Time spent so far 244.86514043807983s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:03<00:00, 24.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 2.830584046430483\n",
      "\n",
      "Time spent so far 369.36715936660767s\n",
      "Best training size = 500\n",
      "Best lags = [1 2 3 4 5 6]\n",
      "Best parameters = {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"c\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6248f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2021-07-03 00:00:00 to 2021-07-03 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:08<00:00, 13.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 129.54395999955935\n",
      "\n",
      "Time spent so far 69.24426078796387s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:22<00:00, 16.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 142.11356751719492\n",
      "\n",
      "Time spent so far 151.81086564064026s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:37<00:00, 19.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 153.27565106806563\n",
      "\n",
      "Time spent so far 251.18474745750427s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:09<00:00, 25.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 156.09126689874714\n",
      "\n",
      "Time spent so far 382.2853310108185s\n",
      "Best training size = 100\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Best parameters = {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"e\", Start = '2021-07-03 00:00:00', End = '2021-07-03 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db652dd",
   "metadata": {},
   "source": [
    "## 2022 Decm 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a95fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:04<00:00, 12.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.0\n",
      "\n",
      "Time spent so far 65.61774110794067s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:09<00:00, 13.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.0\n",
      "\n",
      "Time spent so far 135.4800968170166s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:16<00:00, 15.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 7.4810878087099e-09\n",
      "\n",
      "Time spent so far 212.33551502227783s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:35<00:00, 19.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 4.499994772013018e-07\n",
      "\n",
      "Time spent so far 308.47899985313416s\n",
      "Best training size = 100\n",
      "Best lags = [1]\n",
      "Best parameters = {'n_estimators': 714, 'max_depth': 9, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"p\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f72e330c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:07<00:00, 13.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.607253717204947\n",
      "\n",
      "Time spent so far 67.95103287696838s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:21<00:00, 16.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.49517098346628097\n",
      "\n",
      "Time spent so far 150.12708187103271s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:35<00:00, 19.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 418, 'max_depth': 13, 'max_features': 'log2'}\n",
      "  Backtesting metric: 0.6696254895150052\n",
      "\n",
      "Time spent so far 246.92239832878113s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:04<00:00, 24.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 246, 'max_depth': 14, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 0.7459762414149241\n",
      "\n",
      "Time spent so far 372.6356248855591s\n",
      "Best training size = 500\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Best parameters = {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"c\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c445c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on period from 2022-12-31 00:00:00 to 2022-12-31 23:00:00\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:08<00:00, 13.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 11367.724796243492\n",
      "\n",
      "Time spent so far 69.45063185691833s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:21<00:00, 16.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] \n",
      "  Parameters: {'n_estimators': 713, 'max_depth': 9, 'max_features': 'log2'}\n",
      "  Backtesting metric: 8274.462267029145\n",
      "\n",
      "Time spent so far 152.55445504188538s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [01:39<00:00, 19.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1] \n",
      "  Parameters: {'n_estimators': 412, 'max_depth': 12, 'max_features': 'log2'}\n",
      "  Backtesting metric: 7631.793137423374\n",
      "\n",
      "Time spent so far 252.6315779685974s\n",
      "Number of models compared: 50,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 5/5 [02:09<00:00, 25.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "  Backtesting metric: 3666.4049545676967\n",
      "\n",
      "Time spent so far 383.18541193008423s\n",
      "Best training size = 2000\n",
      "Best lags = [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Best parameters = {'n_estimators': 236, 'max_depth': 20, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "rf_model.tune_hyperparameters(\"e\", Start = '2022-12-31 00:00:00', End = '2022-12-31 23:00:00',train_sizes=[100,500,1000,2000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
